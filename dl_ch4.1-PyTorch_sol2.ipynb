{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution using PyTorch for MNIST database 2\n",
    "\n",
    "Based on PyTorch tutorial [link](https://www.kaggle.com/oddrationale/mnist-in-csv/code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries required for data analysis and visualisation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt    \n",
    "\n",
    "# Dataset and DataLoader are of particular importance as these will \n",
    "# structure the data such that the necessary mathematically operations\n",
    "# required to generate a model can be applied to the data.\n",
    "\n",
    "# For more details review: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    " \n",
    "\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data containing number label and values for pixel hue in a\n",
    "# 28x28 grid\n",
    "\n",
    "training_data = open('mnist_train.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame based on training data\n",
    "\n",
    "training_data_df = pd.read_csv(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample of DateFrame values. Includes label and pixel hue values\n",
    "\n",
    "training_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an MNIST Dataset that outputs an array consisting of the \n",
    "# number label and pixel hues for that number. ToTensor converst this\n",
    "# array to a tensor that can be used for processing by the GPU.\n",
    "\n",
    "\n",
    "\n",
    "class MNIST_Dataset(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        # Create a DataFrame based on MNIST CSV file\n",
    "        num_pix_df = pd.read_csv(path)\n",
    "        # Series of number labels\n",
    "        self.num_labels = num_pix_df['label']\n",
    "        # DF for all pixel values\n",
    "        self.pix_vals = num_pix_df.iloc[:,1:].values \n",
    "        # Hue value of pixel from integer images\n",
    "        self.n_samples = len(num_pix_df)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        #Tuple pixel values and np array of number labels \n",
    "        sample = self.pix_vals[index],np.array(self.num_labels[index]) \n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "# Converts arrays to tensors\n",
    "\n",
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        inputs, target=sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MNIST_Dataset object at 0x7f54e3f69070>\n"
     ]
    }
   ],
   "source": [
    "# Creating Training and Testing sets from my locally stored MNIST csv\n",
    "# files using the MNIST class created above\n",
    "\n",
    "training_path = open('mnist_train.csv')\n",
    "testing_path = open('mnist_test.csv')\n",
    "\n",
    "training_set = MNIST_Dataset(training_path, transform = ToTensor())\n",
    "testing_set = MNIST_Dataset(testing_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f54e3f30580>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here is a visual example of number from the data set\n",
    "\n",
    "example = training_set[0]\n",
    "plt.imshow(example[0].numpy().reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using PyTorch's in-built DataLoader function to structure batches for\n",
    "# training and testing data sets. Dividing the data in this way \n",
    "# improves GPU performance\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "training_loader=DataLoader(training_set,batch_size=100,shuffle=True)\n",
    "testing_loader=DataLoader(testing_set,batch_size=100,shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f54e42b99a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Another visual example, this time a sample from the batch. Since\n",
    "# the data is shuffle it should adjust each time this command is run.\n",
    "\n",
    "plt.imshow(iter(training_loader).next()[0][0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(training_loader).next()[0][0].dtype\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we generate a neural net to perform the matrix operations on the\n",
    "# data. First some presets must be configured\n",
    "\n",
    "\n",
    "# we set this to 1 because the hues are greyscale image\n",
    "input_size=1\n",
    "# first convolution converts 1 channel to 16 channels in feature maps\n",
    "hid1_size=16\n",
    "# then to 32 channels\n",
    "hid2_size=32\n",
    "\n",
    "k_conv_size=5\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class that defines the neutral net. This has two layers and the \n",
    "# forward function defines the process between the two layers to \n",
    "# progressively improve the prediction\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer1=torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(input_size,hid1_size,k_conv_size),\n",
    "        torch.nn.BatchNorm2d(hid1_size),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(kernel_size=2)\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.layer2=torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(hid1_size,hid2_size,k_conv_size),\n",
    "            torch.nn.BatchNorm2d(hid2_size),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.fc=torch.nn.Linear(512,10)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.layer1(x)\n",
    "        \n",
    "        x=self.layer2(x)\n",
    "        # Changing the image into one dimensional tensor for feeding \n",
    "        # the fully connected layers\n",
    "        x=x.reshape(x.shape[0],-1)\n",
    "       \n",
    "        x=self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating the neural net from the GPU you - must be an NVIDIA model\n",
    "\n",
    "model=Net()\n",
    "device=torch.device('cuda')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we generate the loss function, in this case a Cross Entropy Loss\n",
    "\n",
    "lr=1e-3\n",
    "loss_fn=torch.nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=lr,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the number of epochs for the model to run\n",
    "\n",
    "epochs=3\n",
    "loss_values=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3850, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4731, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2775, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1814, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1389, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2109, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1198, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0751, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1087, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2166, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0940, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0666, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1056, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0271, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0549, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Here the pixel hues are converted back to images. I wonder if there\n",
    "# would be a more direct way to analyse the images?\n",
    "\n",
    "\n",
    "targets=np.array([])\n",
    "preds=np.array([])\n",
    "for epoch in range(epochs):\n",
    "    for i,(img,target) in enumerate(training_loader):\n",
    "        img=img.reshape(100,1,28,28).float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output=model(img)\n",
    "        pred=torch.argmax(output,axis=1)\n",
    "#         print(target,pred)\n",
    "        targets=np.hstack([targets,target.cpu().numpy()])\n",
    "        preds=np.hstack([preds,pred.cpu().numpy()])\n",
    "        loss=loss_fn(output,target.to(device))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100==0:\n",
    "            print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9510111111111111"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(targets,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9506141148115714"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(targets,preds,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
